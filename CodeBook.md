# Getting and Cleaning Data Course Project Code Book
mjdata  
July 22, 2015  

**Getting and Cleaning Data Course Project CodeBook**:   

 - The code book called CodeBook.md in the [repo](https://github.com/mjdata/getclean_project.git)
 describes the followings:
 
    -- the tidy data sets [tidy_wide.txt](https://github.com/mjdata/getclean_project.git/tidy_wide.txt) generated by the 
cleaning script [run_analysis.R](https://github.com/mjdata/getclean_project.git/run_analysis.R)
    
    -- the variables of the tidy data sets "tidy_wide.txt"  
    
    -- some transformations performed in [run_analysis.R](https://github.com/mjdata/getclean_project.git/run_analysis.R)
    
 - The [CodeBook.md](https://github.com/mjdata/getclean_project.git/CodeBook.md) is generated by the script [CodeBook.Rmd](https://github.com/mjdata/getclean_project.git/CodeBook.Rmd). 
 
 - CodeBook.md is complement with [README.md](https://github.com/mjdata/getclean_project.git/README.md) each other.

## Project Description

The purpose of this project is to demonstrate ability to collect, work with, 
and clean a data set. The goal is to prepare tidy data that can be used for later 
analysis.  

### Submitted files in the [repo](https://github.com/mjdata/getclean_project.git):

- tidy_wide.txt:    a tidy data sets produced by run_analysis.R.
                    It can be read into R with read.table(header=TRUE)

- run_analysis.R:    Cleans and combines the raw data sets, then generates 
                    a tidy data text file "tidy_wide.txt that meets the 
                    principles of tidy data.
 
- CodeBook.Rmd:      A RMarksown script that creates CodeBook.md
 
- CodeBook.md:       Describes the variables, the data, and transformations or                          works performed in run_analysis.R to clean up the data.

- README.Rmd:        A R Markdown script that creates README.md 

- README.md:         Describes what the script run_analysis.R do and explains how                       the three scripts work and how they are connected.

##Study design and data processing

The course project is designed to do the data cleaning processes such as collecting 
the raw data sets, combining, selecting and cleaning the data sets to create a
tidy data sets, that is ready for further analysis. 

 - Training and test data sets

The raw data sets was originated from the experiments on Human Activity Recognition
Using Smartphones Dataset. The experiments have been carried out with a group of
30 volunteers called subjects. Each person performed six activities
(WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) 
wearing a smartphone (Samsung Galaxy S II) with embedded sensors, accelerometer 
and gyroscope. The obtained dataset has been randomly partitioned into two sets,
where 70% and 30% of the volunteers were selected for generating the training and
test data respectively. That means that training and test data sets are subsets 
of a single type of observational unit.


 - Sensor signals and derived signals
 
The 3-axial time domain sensor signals including 3-axial linear acceleration and
3-axial angular velocity from accelerometer and gyroscope were captured at a 
constant rate. The filtered acceleration signal was then separated into body and 
gravity acceleration signals. Subsequently, the body linear acceleration and
angular velocity were derived in time to obtain Jerk signals. Also the magnitude
of these three-dimensional signals were calculated. Finally a Fast Fourier 
Transform (FFT) was applied to some of these time domain signals to obtain 
frequency domain signals.

 - Features variables

The signals were sampled in fixed-width sliding time windows of 2.56 sec and with 
50% overlap (128 readings/window at 50 Hz). From each window, a vector of features 
was obtained by calculating variables from the time and frequency domain signals. 
The 17 set of variables including mean() and std() estimated from these signals 
form the 561-feature variables of the raw data sets. No unit of measures is for 
features since all features were normalized and bounded within [-1,1]. 
See 'features_info.txt' for more details. 

###Collection of the raw data

The compressed raw data sets have been downloaded mannually from [here]("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"), and unzipped to a subdirectory called "data" under my working directory. 
 
 
#### Brief description of the raw data

 - A single type of observational unit is spread over the multiple tables or files.
 
 - The two data sets, training and test data sets are subsets of a single 
 type of observational unit, Their variables are same. 
 
 - The 561 features variable names represent the 561 different columns. 
 
 - Each features vector is a row on the train and test data text file.   
 
 - Each row represents the measurements of the variables for each activity, 
each subject included in the subset, and for each time window of time series.
 
 - The features values are normalized and bounded within [-1,1]. 
 
####Notes on the raw data sets
 
 -- The files in "/tain/Inertial Signals" and "/test/Inertial Signals" are not
 used for this course project.   
 
 -- A full description of the raw data sets is [available at](http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones)  
 
##Creating the tidy datafile

The tidy datafile "tidy_wide.txt" that meets the principles of tidy data is 
created by the cleaning script [run_analysis.R](https://github.com/mjdata/getclean_project.git/run_analysis.R)
The transformation and processes are described in detail in [README.md](https://github.com/mjdata/getclean_project.git/README.md).

###The datafile "tidy_wide.txt" meets the tidy data principles

The tidy datafile "tidy_wide.txt" is generated by the script run_analysis.R under 
the general guide and principles of tidy data, as described in the references [1](http://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html), [2](https://github.com/jtleek/datasharing#the-tidy-data-set), [3](https://class.coursera.org/getdata-015/forum/thread?thread_id=27).
 
 - **One file per table, one table per file**: 
    The tidy data file "tidy_wide.txt" contains only one tidy data table.
    
 - **Each type of observational unit forms a table**: 
    As described above and also in ReadMe.md, the tidy data table 
    "tidy_wide" is created from the relevant raw data sets of a single type of 
    observational unit scattered over the multiple tables and files. 
    
 - **Each variable forms a column**: 
     In tidy data table "tidy_wide", each column represents one of the 68 variables
     and no one variable is in different columns and no duplicated columns.
      
 - **Each observation forms a row**: 
     In"tidy_wide", each row represents each new observation, i.e. the aggregated 
     average of each of the original 66 variables for each activity and each 
     subject. The 180 rows correspond to the unique values of 6-activity and 
     30-subject pair. No single observation is split over rows or repeated. 
     Each different observation of a variable is in a different row.
      
 - **Appropriately descriptive variable names at the top of the table**: 
     As expalained in ReadMe.md and above, the new variable names describe 
     properly and appropriately each column, with the last level ".average" in the 
     variable names. The new names also include some corrections and 
     transformations for human readability comparied to the original feaures names.
     
 - **Descriptive names for activity**
     The activity is represented by the descriptive names (character strings) in
     the tidy data sets replacing the integer numbers in the raw data sets.
     
 - **Ready for analysis**: 
     "tidy_wide.txt" is a clean, tidy data sets of the selected single
     observatioinal unit. It is nicely ready for further data analysis. 
     
###Cleaning of the data
Short, high-level description of what the cleaning script does. 
[link to the readme document that describes the code in greater detail](https://github.com/mjdata/getclean_project.git/README.md)

The cleaning script run_analysis.R does the followings:

1. Extracting only the measurements on the mean and standard deviation for each
measurement from the traing and the test sets.

2. Merging the extracted training and test sets to create one data set.

3. Naming activity names in the data set using descriptive activity names

4. Creating a tidy data set with the average of each variable for each activity 
and each subject.

5. Labeling the tidy data set with new descriptive variable names.

6. Writing the tidy data sets in a file called "tidy_Wide.txt"


##Description of the variables in the tidy_wide.txt file
General description of the file including:
(you can easily use Rcode for this, just load the dataset and provide the 
information directly form the tidy data file)


  - Dimensions of the datasets

```
## [1] 180  68
```
  - Extracted outputs: head(tidy[, 1:3], 6)

```
## Source: local data frame [6 x 3]
## 
##   activity subject time.body.accelerat.x.mean.average
## 1   laying       1                          0.2215982
## 2   laying       2                          0.2813734
## 3   laying       3                          0.2755169
## 4   laying       4                          0.2735716
## 5   laying       5                          0.2783343
## 6   laying       6                          0.2486565
```
  - Summary of the data (summary(tidy)[, 1:3])

```
##                activity       subject      
##  "laying            :30  " "Min.   : 1.0  "
##  "sitting           :30  " "1st Qu.: 8.0  "
##  "standing          :30  " "Median :15.5  "
##  "walking           :30  " "Mean   :15.5  "
##  "walking_downstairs:30  " "3rd Qu.:23.0  "
##  "walking_upstairs  :30  " "Max.   :30.0  "
##  time.body.accelerat.x.mean.average
##  "Min.   :0.2216  "                
##  "1st Qu.:0.2716  "                
##  "Median :0.2770  "                
##  "Mean   :0.2748  "                
##  "3rd Qu.:0.2800  "                
##  "Max.   :0.3015  "
```

  - Variables present in the dataset

```
##  [1] "activity"                                       
##  [2] "subject"                                        
##  [3] "time.body.accelerat.x.mean.average"             
##  [4] "time.body.accelerat.y.mean.average"             
##  [5] "time.body.accelerat.z.mean.average"             
##  [6] "time.body.accelerat.x.std.average"              
##  [7] "time.body.accelerat.y.std.average"              
##  [8] "time.body.accelerat.z.std.average"              
##  [9] "time.gravity.accelerat.x.mean.average"          
## [10] "time.gravity.accelerat.y.mean.average"          
## [11] "time.gravity.accelerat.z.mean.average"          
## [12] "time.gravity.accelerat.x.std.average"           
## [13] "time.gravity.accelerat.y.std.average"           
## [14] "time.gravity.accelerat.z.std.average"           
## [15] "time.body.accelerat.jerk.x.mean.average"        
## [16] "time.body.accelerat.jerk.y.mean.average"        
## [17] "time.body.accelerat.jerk.z.mean.average"        
## [18] "time.body.accelerat.jerk.x.std.average"         
## [19] "time.body.accelerat.jerk.y.std.average"         
## [20] "time.body.accelerat.jerk.z.std.average"         
## [21] "time.body.gyroscope.x.mean.average"             
## [22] "time.body.gyroscope.y.mean.average"             
## [23] "time.body.gyroscope.z.mean.average"             
## [24] "time.body.gyroscope.x.std.average"              
## [25] "time.body.gyroscope.y.std.average"              
## [26] "time.body.gyroscope.z.std.average"              
## [27] "time.body.gyroscope.jerk.x.mean.average"        
## [28] "time.body.gyroscope.jerk.y.mean.average"        
## [29] "time.body.gyroscope.jerk.z.mean.average"        
## [30] "time.body.gyroscope.jerk.x.std.average"         
## [31] "time.body.gyroscope.jerk.y.std.average"         
## [32] "time.body.gyroscope.jerk.z.std.average"         
## [33] "time.body.accelerat.magnitude.mean.average"     
## [34] "time.body.accelerat.magnitude.std.average"      
## [35] "time.gravity.accelerat.magnitude.mean.average"  
## [36] "time.gravity.accelerat.magnitude.std.average"   
## [37] "time.body.accelerat.jerk.magnitude.mean.average"
## [38] "time.body.accelerat.jerk.magnitude.std.average" 
## [39] "time.body.gyroscope.magnitude.mean.average"     
## [40] "time.body.gyroscope.magnitude.std.average"      
## [41] "time.body.gyroscope.jerk.magnitude.mean.average"
## [42] "time.body.gyroscope.jerk.magnitude.std.average" 
## [43] "freq.body.accelerat.x.mean.average"             
## [44] "freq.body.accelerat.y.mean.average"             
## [45] "freq.body.accelerat.z.mean.average"             
## [46] "freq.body.accelerat.x.std.average"              
## [47] "freq.body.accelerat.y.std.average"              
## [48] "freq.body.accelerat.z.std.average"              
## [49] "freq.body.accelerat.jerk.x.mean.average"        
## [50] "freq.body.accelerat.jerk.y.mean.average"        
## [51] "freq.body.accelerat.jerk.z.mean.average"        
## [52] "freq.body.accelerat.jerk.x.std.average"         
## [53] "freq.body.accelerat.jerk.y.std.average"         
## [54] "freq.body.accelerat.jerk.z.std.average"         
## [55] "freq.body.gyroscope.x.mean.average"             
## [56] "freq.body.gyroscope.y.mean.average"             
## [57] "freq.body.gyroscope.z.mean.average"             
## [58] "freq.body.gyroscope.x.std.average"              
## [59] "freq.body.gyroscope.y.std.average"              
## [60] "freq.body.gyroscope.z.std.average"              
## [61] "freq.body.accelerat.magnitude.mean.average"     
## [62] "freq.body.accelerat.magnitude.std.average"      
## [63] "freq.body.accelerat.jerk.magnitude.mean.average"
## [64] "freq.body.accelerat.jerk.magnitude.std.average" 
## [65] "freq.body.gyroscope.magnitude.mean.average"     
## [66] "freq.body.gyroscope.magnitude.std.average"      
## [67] "freq.body.gyroscope.jerk.magnitude.mean.average"
## [68] "freq.body.gyroscope.jerk.magnitude.std.average"
```
 - In the new tidy data sets, the variable 1 "activity" and variable 2 "subject"
 form the ID field, and the variable 3 to 68 form the features variable field.
 
###Variable 1

```
## [1] "activity"
```
The variable 1 describes the six activities of the subjects for the measurements. 
 
 - Class of the variable 1

```
## [1] "factor"
```
 - levels of the variable

```
## [1] "laying"             "sitting"            "standing"          
## [4] "walking"            "walking_downstairs" "walking_upstairs"
```
 - Unit of measurement (if no unit of measurement list this as well)

###Variable 2

```
## [1] "subject"
```
Variable 2 describes 30 subjects (participants) wearing smartphones 
 - Class of the variable

```
## [1] "integer"
```
 - Unique values of the variable

```
##  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
## [24] 24 25 26 27 28 29 30
```
 - Unit of measurement(if no unit of measurement list this as well)
 
###Variable 3 to 68
The variables 3 to 68 describe the aggregated average of the 66 selected 
features variables averaged over time windows for each activity and each subject, 
as Illustrated with variable 3. 

```
## [1] "time.body.accelerat.x.mean.average"
```
 - Class of the variable

```
## [1] "numeric"
```
 - Number of Unique values of the variable

```
## [1] 180
```
 - No unit of measurement is for variables[3:68] since all features were normalized 
and bounded within [-1,1].
    
 - In case names follow some schema, describe how entries were constructed 
    
####Constructing the new variable names
The names of the variables [3:68] are constructed based on the original 
features names with some corrections and transformations, including:
    
 -- One more level **{average}** is added at the end, to describe properly the new 
variables of the new tidy data as the aggregated mean of each original feautures
variable averaged over time windows for each activity and each subject.
          
 -- {X, Y, Z} and {mean(), std()} are switched for proper levels of schema.
      
 -- body replaced BodyBody as a correction
      
 -- {time, freq} replaced {^t, ^f}  where freq represents frequency
      
 -- {Accelerat, Gyroscope, magnitude} replaced {Acc, Gyro, Mag}
     
 -- {mean, std} replaced {mean(), std()}

 -- transformed to lower cases and used "." as separator.


####Schema of the new variavle names:
    
Among the variable[3:68] names, 42 have 6-level and 26 have 7-level descriptors.
   
* 6-level schema:
   
    1. level 1, {time, freq}: time or frequency domain. 
                    
    2. level 2, {body, graviry}: Body acceleration and Gravity acceleration 
    
    3. level 3, {accelerat, gyroscope}: Sensor signals including 3-axial linear
       Acceleration signals from Accelerometer and Signal measured by Gyroscope.
             
    4. level 4, {x, y, z, magnitude}: [XYZ] components and magnitude of the 
    acceleration or jerk.
    
    5. level 5, {mean, std}: mean() and std() features obtained by calculating
    previous 4-level variables from the time and frequency domain over each time 
    window.
             
    6. level 6, **{averge}**: mean of the previous 5-level variables for each subject
    and each activity averaged over time windows.
 
* 7-level schema:
     
    1. level 1, {time, freq}: time or frequency domain. 
                    
    2. level 2, {body, graviry}: Body acceleration and Gravity acceleration 
    
    3. level 3, {accelerat, gyroscopy}: Sensor signals including 3-axial
    linear Acceleration signal from Accelerometer and Signal measured by Gyroscope.
     
    4. level 4, **{jerk}**: jerk signals derived in time from acceleration 
     
    5. level 5, {x, y, z, magnitude}: [XYZ] components of the acceleration and
    Jerk,and  magnitude of these 3-dimentional signals.
                 
    6. level 6, {mean, std}: mean() and std() features obtained by calculating
    previous 5-level variables from the time and frequency domain for each time 
    window. 
     
    7. level 7, **{average}**: mean of the previous 6-level variables for each subject
    and each activity averaged over time windows.  
    
####Notes on the CodeBook template:
This CodeBook is based on the [Codebook template that can be used in the Getting 
and Cleaning Data project](https://gist.github.com/JorisSchut/dbc1fc0402f28cad9b41)
listed on http://datasciencespecialization.github.io/getclean/

##Annex
If you used any code in the codebook that had the echo=FALSE attribute post this
here (make sure you set the results parameter to 'hide' as you do not want the 
results to show again)

